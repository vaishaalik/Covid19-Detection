{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid-19 Detector",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F6Ina2y3-it",
        "outputId": "afaf9f8c-4bdd-4fe1-b197-5b4c87a9fd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "!wget https://www.dropbox.com/sh/l1uzqobod13zryu/AACJju8_cJUNFOioKxBPTVFua?dl=0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 12:50:10--  https://www.dropbox.com/sh/l1uzqobod13zryu/AACJju8_cJUNFOioKxBPTVFua?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/l1uzqobod13zryu/AACJju8_cJUNFOioKxBPTVFua [following]\n",
            "--2020-10-12 12:50:10--  https://www.dropbox.com/sh/raw/l1uzqobod13zryu/AACJju8_cJUNFOioKxBPTVFua\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc1a01651befc88cdf7b510b454.dl.dropboxusercontent.com/zip_download_get/AkhTa0hx5emhJD1v3EqXg_pzLnpaMOxIMKZ3Pos67QTSwSSiXusVSA96X8YXkdEyBPeW_J-Pzo1xzt-a3qsL0BdSKwRhcQTtjyVUNE-t9S9Xdg [following]\n",
            "--2020-10-12 12:50:12--  https://ucc1a01651befc88cdf7b510b454.dl.dropboxusercontent.com/zip_download_get/AkhTa0hx5emhJD1v3EqXg_pzLnpaMOxIMKZ3Pos67QTSwSSiXusVSA96X8YXkdEyBPeW_J-Pzo1xzt-a3qsL0BdSKwRhcQTtjyVUNE-t9S9Xdg\n",
            "Resolving ucc1a01651befc88cdf7b510b454.dl.dropboxusercontent.com (ucc1a01651befc88cdf7b510b454.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucc1a01651befc88cdf7b510b454.dl.dropboxusercontent.com (ucc1a01651befc88cdf7b510b454.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 388387890 (370M) [application/zip]\n",
            "Saving to: ‘AACJju8_cJUNFOioKxBPTVFua?dl=0’\n",
            "\n",
            "AACJju8_cJUNFOioKxB 100%[===================>] 370.40M  2.50MB/s    in 90s     \n",
            "\n",
            "2020-10-12 12:51:42 (4.11 MB/s) - ‘AACJju8_cJUNFOioKxBPTVFua?dl=0’ saved [388387890/388387890]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa-gSJRj4fCg"
      },
      "source": [
        "!unzip Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3g7U06Q5I3L"
      },
      "source": [
        "TRAIN_PATH=\"Dataset/Train\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hKqKthE55Sa"
      },
      "source": [
        "VAL_PATH=\"Dataset/Test\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dgybv4B59B6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKzXzTwI6EAF"
      },
      "source": [
        "#CNN based model in keras-its going to be a sequential model\n",
        "#So,what happens in building a CNN?We have multiple layers.1st layer has some number of filters,the next layer's got some more filters, & so on.\n",
        "#Thus, its a layered architecture."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsS04omp6J3p"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu', input_shape=(224,224,3)))\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "#till here we have 4 Conc layers, now we'll add the dense layers.\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "#used to detect feature in very tiny areas of the image.Its gonna learn a hidden pattern.As you go deeper into the layered network,\n",
        "#the receptive feild of the CNN increases. So, the feature it extracts are quite a bigger part of the original picture.\n",
        "#(3x3) is the standard kernel size picked\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D6Z5fSi60Yx",
        "outputId": "7663bcb4-d81d-4770-db72-5f925c4001e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 220, 220, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 108, 108, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 52, 52, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                5537856   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,668,097\n",
            "Trainable params: 5,668,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t245wDq77HEX"
      },
      "source": [
        "#1:09:45"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eIGUCYQuT03"
      },
      "source": [
        "#Train from scratch\n",
        "#so we'll use the keras image data generator library to make the data ready for the model\n",
        "train_datagen=image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "test_dataset=image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnZEzJGGwEMo",
        "outputId": "b487175c-5fdd-4a81-ed2c-fe1ddd95e8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#creating actual generator function\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    'Train',\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 314 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZiy2DCIxPEv",
        "outputId": "4f75553b-c2b5-48ea-957e-b31865a870c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Covid': 0, 'Normal': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24qNOOTMyKjs",
        "outputId": "123eacde-61c5-4449-8b09-65842894e0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator=test_dataset.flow_from_directory(\n",
        "    'Val',\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 78 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb2KjkxHy28Z",
        "outputId": "335850d6-eb11-4006-ee7e-3e78ab337a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "hist = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8,\n",
        "    epochs=20,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=2\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-2700de3a1021>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 1.3477 - accuracy: 0.6000 - val_loss: 0.6613 - val_accuracy: 0.4844\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.5675 - accuracy: 0.7040 - val_loss: 0.5274 - val_accuracy: 0.9531\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.3469 - accuracy: 0.8360 - val_loss: 0.3025 - val_accuracy: 0.9219\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.2651 - accuracy: 0.8867 - val_loss: 0.1407 - val_accuracy: 0.9531\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1428 - accuracy: 0.9560 - val_loss: 0.2205 - val_accuracy: 0.9219\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1167 - accuracy: 0.9600 - val_loss: 0.0929 - val_accuracy: 0.9688\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1730 - accuracy: 0.9320 - val_loss: 0.1746 - val_accuracy: 0.9531\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.0771 - accuracy: 0.9640 - val_loss: 0.1267 - val_accuracy: 0.9688\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1884 - accuracy: 0.9440 - val_loss: 0.1678 - val_accuracy: 0.9531\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1506 - accuracy: 0.9440 - val_loss: 0.1850 - val_accuracy: 0.9531\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1519 - accuracy: 0.9560 - val_loss: 0.1584 - val_accuracy: 0.9531\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.0871 - accuracy: 0.9766 - val_loss: 0.1644 - val_accuracy: 0.9375\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1013 - accuracy: 0.9680 - val_loss: 0.1631 - val_accuracy: 0.9531\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1113 - accuracy: 0.9720 - val_loss: 0.2660 - val_accuracy: 0.9062\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1641 - accuracy: 0.9440 - val_loss: 0.1408 - val_accuracy: 0.9531\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1480 - accuracy: 0.9492 - val_loss: 0.3046 - val_accuracy: 0.8594\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.1815 - accuracy: 0.9200 - val_loss: 0.1863 - val_accuracy: 0.9375\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1605 - accuracy: 0.9400 - val_loss: 0.2610 - val_accuracy: 0.9062\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1484 - accuracy: 0.9560 - val_loss: 0.1619 - val_accuracy: 0.9531\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1384 - accuracy: 0.9453 - val_loss: 0.1991 - val_accuracy: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfexxjwX0RA6"
      },
      "source": [
        "#Class Activation Maps\n",
        "#Grad-CAM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1nNbVLn2TzG",
        "outputId": "f1c22160-41e8-496b-b2f4-3815c373fc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model.evaluate_generator(train_generator)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-e4ade065aa26>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08754798024892807, 0.9745222926139832]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgathw9n2ZDe",
        "outputId": "997bd2fc-2222-45ff-8e08-4893a64d5987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.evaluate_generator(validation_generator)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16756571829319, 0.9487179517745972]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f75sYx1U2kxB",
        "outputId": "63461e61-d755-41f4-84d9-aa34a16a9518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model') "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocqOdAT62wTT"
      },
      "source": [
        "import os"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANkz50Kx3-Wg",
        "outputId": "5f9327b6-0593-4555-d3f8-bd02e3fa5b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Covid': 0, 'Normal': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfzXeYh850Vz"
      },
      "source": [
        "y_actual=[]\n",
        "y_test=[]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXO1SqyH53cu",
        "outputId": "7468b266-a5ea-4d27-a54d-781432295295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "for i in os.listdir(\"./Val/Normal/\"):\n",
        "  img=image.load_img(\"./Val/Normal/\"+i, target_size=(224,224))\n",
        "  img=image.img_to_array(img)\n",
        "  img=np.expand_dims(img,axis=0)\n",
        "  p=model.predict_classes(img)\n",
        "  y_test.append(p[0,0])\n",
        "  y_actual.append(1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-f9edb15df638>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaW4zrhp6qzs"
      },
      "source": [
        "for i in os.listdir(\"./Val/Covid/\"):\n",
        "  img=image.load_img(\"./Val/Covid/\"+i, target_size=(224,224))\n",
        "  img=image.img_to_array(img)\n",
        "  img=np.expand_dims(img,axis=0)\n",
        "  p=model.predict_classes(img)\n",
        "  y_test.append(p[0,0])\n",
        "  y_actual.append(0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmMuK9oX6vck"
      },
      "source": [
        "y_actual=np.array(y_actual)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cizyXNp97Sb9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbvcXJmo7UkM"
      },
      "source": [
        "cm=confusion_matrix(y_actual, y_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOV1hXlf7ZWz"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3XMxeGx7dWk",
        "outputId": "442fc973-65d4-4e48-dc77-2093d10acf62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "sns.heatmap(cm, cmap='plasma',annot=True)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5400fd1240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS6tATF17esD"
      },
      "source": [
        "#0->covid, 1->normal\n",
        "# TP, FN\n",
        "# FP,TN"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
